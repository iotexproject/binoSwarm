# ==================================
#      SERVER & DATABASE
# ==================================

# --- General Server ---
SERVER_PORT=3000
EXPRESS_MAX_PAYLOAD=            # Default: 100kb

# --- Database & Cache ---
CACHE_STORE=database            # Defaults to database. Other available cache store: redis and filesystem
REDIS_URL=                      # Redis URL - could be a local redis instance or cloud hosted redis. Also support rediss:// URLs
ENFORCE_DB_SSL=false
CA_CERT_PATH=

# ==================================
#      AI & LLM PROVIDERS
# ==================================

# --- General AI Settings ---
TRANSCRIPTION_PROVIDER=         # Default: local (possible values: openai, deepgram, local)
TOKENIZER_MODEL=                # Specify the tokenizer model to be used.
TOKENIZER_TYPE=                 # Options: tiktoken (for OpenAI models) or auto (AutoTokenizer from Hugging Face for non-OpenAI models). Default: tiktoken.

# --- Anthropic ---
ANTHROPIC_API_KEY=              # For Claude
SMALL_ANTHROPIC_MODEL=          # Default: claude-3-haiku-20240307
MEDIUM_ANTHROPIC_MODEL=         # Default: claude-3-5-sonnet-20241022
LARGE_ANTHROPIC_MODEL=          # Default: claude-3-5-sonnet-20241022

# --- Deepgram ---
DEEPGRAM_API_KEY=

# --- DeepSeek ---
DEEPSEEK_API_KEY=               # Your DeepSeek API key
DEEPSEEK_API_URL=               # Default: https://api.deepseek.com
SMALL_DEEPSEEK_MODEL=           # Default: deepseek-chat
MEDIUM_DEEPSEEK_MODEL=          # Default: deepseek-chat
LARGE_DEEPSEEK_MODEL=           # Default: deepseek-chat

# --- ElevenLabs (Speech Synthesis) ---
ELEVENLABS_XI_API_KEY=          # API key from elevenlabs
ELEVENLABS_MODEL_ID=eleven_multilingual_v2
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_VOICE_STABILITY=0.5
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.9
ELEVENLABS_VOICE_STYLE=0.66
ELEVENLABS_VOICE_USE_SPEAKER_BOOST=false
ELEVENLABS_OPTIMIZE_STREAMING_LATENCY=4
ELEVENLABS_OUTPUT_FORMAT=pcm_16000

# --- Grok ---
GROK_API_KEY=                   # GROK/xAI API Key
SMALL_GROK_MODEL=               # Default: grok-2-1212
MEDIUM_GROK_MODEL=              # Default: grok-2-1212
LARGE_GROK_MODEL=               # Default: grok-2-1212
EMBEDDING_GROK_MODEL=           # Default: grok-2-1212

# --- Livepeer ---
LIVEPEER_GATEWAY_URL=           # Free inference gateways and docs: https://livepeer-eliza.com/
LIVEPEER_IMAGE_MODEL=           # Default: ByteDance/SDXL-Lightning

# --- LlamaLocal ---
LLAMALOCAL_PATH=                # Default: "" which is the current directory in plugin-node/dist/ which gets destroyed and recreated on every build

# --- Nineteen.ai ---
NINETEEN_AI_API_KEY=            # Get a free api key from https://nineteen.ai/app/api
SMALL_NINETEEN_AI_MODEL=        # Default: unsloth/Llama-3.2-3B-Instruct
MEDIUM_NINETEEN_AI_MODEL=       # Default: unsloth/Meta-Llama-3.1-8B-Instruct
LARGE_NINETEEN_AI_MODEL=        # Default: hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
IMAGE_NINETEEN_AI_MODE=         # Default: dataautogpt3/ProteusV0.4-Lightning

# --- Ollama (Local) ---
OLLAMA_SERVER_URL=              # Default: localhost:11434
OLLAMA_MODEL=
USE_OLLAMA_EMBEDDING=           # Set to TRUE for OLLAMA/1024, leave blank for local
OLLAMA_EMBEDDING_MODEL=         # Default: mxbai-embed-large
SMALL_OLLAMA_MODEL=             # Default: llama3.2
MEDIUM_OLLAMA_MODEL=            # Default: hermes3
LARGE_OLLAMA_MODEL=             # Default: hermes3:70b

# --- OpenAI ---
OPENAI_API_KEY=                 # OpenAI API key, starting with sk-
OPENAI_API_URL=                 # OpenAI API Endpoint (optional), Default: https://api.openai.com/v1
USE_OPENAI_EMBEDDING=           # Set to TRUE for OpenAI/1536, leave blank for local
SMALL_OPENAI_MODEL=             # Default: gpt-4o-mini
MEDIUM_OPENAI_MODEL=            # Default: gpt-4o
LARGE_OPENAI_MODEL=             # Default: gpt-4o
EMBEDDING_OPENAI_MODEL=         # Default: text-embedding-3-small
IMAGE_OPENAI_MODEL=             # Default: dall-e-3

# --- OpenRouter ---
OPENROUTER_API_KEY=             # OpenRouter API Key
OPENROUTER_MODEL=               # Default: uses hermes 70b/405b
SMALL_OPENROUTER_MODEL=
MEDIUM_OPENROUTER_MODEL=
LARGE_OPENROUTER_MODEL=
FAST_OPENROUTER_MODEL=

# --- Venice ---
VENICE_API_KEY=                 # generate from venice settings
SMALL_VENICE_MODEL=             # Default: llama-3.3-70b
MEDIUM_VENICE_MODEL=            # Default: llama-3.3-70b
LARGE_VENICE_MODEL=             # Default: llama-3.1-405b
IMAGE_VENICE_MODEL=             # Default: fluently-xl

# ==================================
#      CLIENT INTEGRATIONS
# ==================================

# --- Discord ---
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=              # Bot token
DISCORD_VOICE_CHANNEL_ID=       # The ID of the voice channel the bot should join (optional)

# --- Telegram ---
TELEGRAM_BOT_TOKEN=

# --- Twitter/X ---
TWITTER_USERNAME=               # Account username
TWITTER_PASSWORD=               # Account password
TWITTER_EMAIL=                  # Account email
TWITTER_2FA_SECRET=
TWITTER_RETRY_LIMIT=            # Maximum retry attempts for Twitter login
# Polling & Action Settings
TWITTER_POLL_INTERVAL=120       # How often (in seconds) the bot should check for interactions
TWITTER_SEARCH_ENABLE=FALSE     # Enable timeline search, WARNING this greatly increases your chance of getting banned
TWITTER_TARGET_USERS=           # Comma separated list of Twitter user names to interact with
ACTION_INTERVAL=                # Interval in minutes between action processing runs (default: 5 minutes)
ENABLE_ACTION_PROCESSING=false  # Set to true to enable the action processing loop
MAX_ACTIONS_PROCESSING=1        # Maximum number of actions (e.g., retweets, likes) to process in a single cycle
ACTION_TIMELINE_TYPE=foryou     # Type of timeline to interact with. Options: "foryou" or "following". Default: "foryou"
# Post Interval Settings
POST_INTERVAL_MIN=              # Default: 90 (in minutes)
POST_INTERVAL_MAX=              # Default: 180 (in minutes)
POST_IMMEDIATELY=               # Default: false
# Tweet Approval Workflow (via Discord)
TWITTER_APPROVAL_ENABLED=false  # Enable or disable Twitter approval logic. Default is false
TWITTER_APPROVAL_DISCORD_CHANNEL_ID= # Channel ID for the Discord bot to listen and send approval messages
TWITTER_APPROVAL_DISCORD_BOT_TOKEN= # Discord bot token (can be different from DISCORD_API_TOKEN)
TWITTER_APPROVAL_CHECK_INTERVAL=60000  # Default: 60 seconds

# ==================================
#   PLUGINS & EXTERNAL SERVICES
# ==================================

# --- AWS S3 (File Upload) ---
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
AWS_S3_BUCKET=
AWS_S3_UPLOAD_PATH=

# --- Crypto (EVM) ---
EVM_PRIVATE_KEY=
EVM_PROVIDER_URL=

# --- Tavily (Web Search) ---
TAVILY_API_KEY=