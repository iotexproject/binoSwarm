# ==================================
#      SERVER & CORE
# ==================================

# --- General & Logging ---
SERVER_PORT=3000
VERBOSE=true                    # Enables debug level logs
EXPRESS_MAX_PAYLOAD=100kb       # Default: 100kb

# --- Database & Cache ---
POSTGRES_URL=postgres://user:password@host:port/database # PostgreSQL connection URL
CACHE_STORE=database            # Defaults to database. Other available cache store: redis and filesystem
REDIS_URL=                      # Redis URL (e.g., redis://localhost:6379)
ENFORCE_DB_SSL=true             # Set to true to enforce SSL connection to the database
CA_CERT_NAME=ca.crt             # Path to the CA certificate file for DB SSL

# --- Rate Limiting & Retention ---
RATE_LIMIT_MESSAGE_WINDOW_MS=60000  # Window for message rate limits in milliseconds (e.g., 60000 = 1 minute)
RATE_LIMIT_MESSAGE_MAX=100          # Max messages per window per user
RATE_LIMIT_STREAM_WINDOW_MS=60000   # Window for streaming endpoint rate limits in milliseconds
RATE_LIMIT_STREAM_MAX=100           # Max streaming requests per window per user
MESSAGE_RETENTION_DAYS=5        # How many days to keep user messages in the database
MAX_USER_MESSAGES=5             # Max number of recent messages to keep per user for context

# ==================================
#      AI & LLM PROVIDERS
# ==================================

# --- General AI Settings ---
TOKENIZER_MODEL=gpt-4           # Specify the tokenizer model to be used.
TOKENIZER_TYPE=tiktoken         # Options: tiktoken (OpenAI) or auto (Hugging Face).
TRANSCRIPTION_PROVIDER=local    # Default: local (options: openai, deepgram, local)

# --- OpenAI ---
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx # OpenAI API key
OPENAI_API_URL=                 # OpenAI API Endpoint (optional), Default: https://api.openai.com/v1
USE_OPENAI_EMBEDDING=true       # Set to true for OpenAI/1536, leave blank for local
SMALL_OPENAI_MODEL=gpt-4o-mini
MEDIUM_OPENAI_MODEL=gpt-4o
LARGE_OPENAI_MODEL=gpt-4.1      # Example: gpt-4-turbo or gpt-4.1
EMBEDDING_OPENAI_MODEL=text-embedding-3-small
IMAGE_OPENAI_MODEL=dall-e-3

# --- Anthropic (Claude) ---
ANTHROPIC_API_KEY=              # For Claude models
SMALL_ANTHROPIC_MODEL=claude-3-haiku-20240307
MEDIUM_ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
LARGE_ANTHROPIC_MODEL=claude-3-opus-20240229
FAST_ANTHROPIC_MODEL=claude-3-haiku-20240307 # Used for fast responses, e.g., in voice interactions

# --- DeepSeek ---
DEEPSEEK_API_KEY=               # Your DeepSeek API key
DEEPSEEK_API_URL=https://api.deepseek.com
SMALL_DEEPSEEK_MODEL=deepseek-chat
MEDIUM_DEEPSEEK_MODEL=deepseek-chat
LARGE_DEEPSEEK_MODEL=deepseek-chat

# --- Grok ---
GROK_API_KEY=                   # GROK/xAI API Key
SMALL_GROK_MODEL=grok-2-1212
MEDIUM_GROK_MODEL=grok-2-1212
LARGE_GROK_MODEL=grok-2-1212
FAST_GROK_MODEL=                # Model for fast voice responses, e.g., grok-3-mini-fast-beta

# --- OpenRouter ---
OPENROUTER_API_KEY=             # OpenRouter API Key
OPENROUTER_MODEL=google/gemini-flash-1.5 # Model used as default
SMALL_OPENROUTER_MODEL=google/gemini-flash-1.5
MEDIUM_OPENROUTER_MODEL=google/gemini-pro-1.5
LARGE_OPENROUTER_MODEL=google/gemini-pro-1.5
FAST_OPENROUTER_MODEL=google/gemini-flash-1.5 # Model for fast voice responses

# --- Together AI ---
TOGETHER_API_KEY=               # Your Together AI API key

# --- Ollama (Local) ---
OLLAMA_SERVER_URL=http://localhost:11434
OLLAMA_MODEL=llama3
USE_OLLAMA_EMBEDDING=           # Set to TRUE for OLLAMA/1024, leave blank for local
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large
SMALL_OLLAMA_MODEL=llama3
MEDIUM_OLLAMA_MODEL=llama3
LARGE_OLLAMA_MODEL=llama3:70b

# --- Speech Synthesis (TTS) & Transcription ---
ELEVENLABS_XI_API_KEY=          # API key from elevenlabs
ELEVENLABS_MODEL_ID=eleven_multilingual_v2
ELEVENLABS_VOICE_ID=            # Voice ID to use (e.g., "Zlb1dXrM653N07WRdFW3" for Joseph)
ELEVENLABS_VOICE_STABILITY=0.5
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.9
ELEVENLABS_VOICE_STYLE=0
ELEVENLABS_VOICE_USE_SPEAKER_BOOST=false
ELEVENLABS_OPTIMIZE_STREAMING_LATENCY=4
ELEVENLABS_OUTPUT_FORMAT=pcm_16000

DEEPGRAM_API_KEY=               # API key for Deepgram services (e.g., transcription)

# ==================================
#      RAG & KNOWLEDGE BASE
# ==================================

# --- Vector DB (Pinecone) ---
PINECONE_API_KEY=               # Your Pinecone API key
PINECONE_INDEX=my-knowledge-base # Name of the Pinecone index to use

# --- RAG Settings ---
DEFAULT_RAG_MATCH_THRESHOLD=0.2 # Minimum similarity score for a knowledge chunk to be considered a match
DEFAULT_RAG_MATCH_COUNT=10      # Number of matching chunks to retrieve from the knowledge base

# --- Knowledge Sources ---
SENTAI_SOURCES=depin,news,l1-data # Comma-separated data categories for agent context
WEATHER_CITIES="New York,Los Angeles,Chicago" # Weather data for agent context if "weather data sourse is enabled"

# ==================================
#      CLIENT INTEGRATIONS
# ==================================

# --- Discord ---
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=              # Bot token
DISCORD_VOICE_CHANNEL_ID=       # The ID of the voice channel the bot should join (optional)
DISCORD_MODS_ROLE_ID=           # Optional mods role id, if enabled in discordMessageHandler prompt the agent can tag mods

# --- Telegram ---
TELEGRAM_BOT_TOKEN=

# --- Twitter/X ---
TWITTER_USERNAME=               # Account username
# X API V2
TWITTER_BEARER_TOKEN=AAA        # Bearer for app only requests
TWITTER_API_KEY=                # user context authentication
TWITTER_API_SECRET=             # user context authentication
TWITTER_ACCESS_TOKEN=           # user context authentication
TWITTER_ACCESS_TOKEN_SECRET=    # user context authentication
# Polling, Searching & Action Settings
TWITTER_POLL_INTERVAL=1200      # How often (in seconds) the bot should check for interactions
TWITTER_SEARCH_ENABLE=TRUE      # Enable timeline search based on search terms
TWITTER_SEARCH_TERMS=iotex,depin # Comma-separated keywords to search for
TWITTER_TARGET_USERS= # Comma-separated list of Twitter user names to interact with
TWITTER_KNOWLEDGE_USERS=        # Comma-separated Twitter usernames for the agent to learn from
ACTION_INTERVAL=30              # Interval in minutes between action processing runs
ENABLE_ACTION_PROCESSING=true   # Set to true to enable the action processing loop (likes, retweets)
MAX_ACTIONS_PROCESSING=5        # Maximum number of actions to process in a single cycle
ACTION_TIMELINE_TYPE=foryou     # Timeline to interact with. Options: "foryou" or "following".
# Post Settings
TWITTER_POST_ENABLED=TRUE       # Enable the agent to post new tweets, false by default
POST_INTERVAL_MIN=15            # Minimum time in minutes between posts
POST_INTERVAL_MAX=30            # Maximum time in minutes between posts
POST_IMMEDIATELY=false

# --- Discourse ---
DISCOURSE_API_KEY=
DISCOURSE_API_USERNAME=
DISCOURSE_WEBHOOK_SECRET=
DISCOURSE_BASE_URL=             # e.g., https://community.example.com

# ==================================
#   PLUGINS & EXTERNAL SERVICES
# ==================================

# --- Meme Generation ---
IMGFLIP_USERNAME=               # Your Imgflip account username
IMGFLIP_PASSWORD=               # Your Imgflip account password

# --- Agent Payments (402 Protocol) ---
X402_PAYMENT_RECEIVER=          # 0x address for receiving payments
X402_PRICE_FOR_PROTECTED_ROUTE_USDC="$0.001" # Price for accessing protected routes
X402_NETWORK=iotex              # Network for payments (e.g., iotex, polygon)
X402_FACILITATOR_URL=http://localhost:8001/facilitator # URL of the payment facilitator

# --- AWS S3 (File Storage) ---
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
AWS_S3_BUCKET=
AWS_S3_UPLOAD_PATH=

# --- Crypto (EVM) ---
EVM_PRIVATE_KEY=
EVM_PROVIDER_URL=https://babel-api.testnet.iotex.io

# --- Web & Data Services ---
NEWSAPI_API_KEY=                # For news plugin/tool
MAPBOX_ACCESS_TOKEN=            # For map-related tools
NUBILA_API_KEY=                 # For external tools
QUICKSILVER_URL=http://167.99.225.251:8000 # URL for Quicksilver service
API_V2_KEY=                     # IoTeX analytics API key
TAVILY_API_KEY=

# --- Membase ---
MEMBASE_ACCOUNT=
MEMBASE_HUB=https://testnet.hub.membase.io

# --- Disclaimer ---
AGENT_DISCLAIMER="Disclaimer: This chatbot is intended for general information..."

# ==================================
#    OBSERVABILITY & METERING
# ==================================

# --- Langfuse ---
LANGFUSE_SECRET_KEY=
LANGFUSE_PUBLIC_KEY=
LANGFUSE_BASEURL=https://us.cloud.langfuse.com
LANGFUSE_ENV=development

# --- OpenMeter ---
OPENMETER_API_KEY=
OPENMETER_SUBJECT=my-agent

# --- PII Redactor ---
PII_REDACTION=                  # true | false (default false)
PII_MODEL_ID=                   # default jammmmmm/pii
PII_DEBUG=                      # true | false (default false)
PII_CONFIDENCE_THRESHOLD=   # default 0.8
PII_AGGREGATION_STRATEGY=       # none | first | average | max | simple (default simple)

MESSAGE_RETENTION_DAYS=
MAX_USER_MESSAGES=